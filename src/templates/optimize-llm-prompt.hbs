# LLM Prompt Optimization

## Objective
As an elite prompt engineer, your task is to significantly enhance the effectiveness and clarity of the given prompt for
optimal LLM interaction.

## Input Prompt

<input_prompt>
  {{multiline_prompt}}
</input_prompt>

## Optimization Process
1. Analyze the input prompt for clarity, specificity, and potential ambiguities
2. Apply advanced prompting techniques (e.g., Chain-of-Thought, Few-Shot Learning)
3. Enhance the prompt's structure and flow
4. Incorporate relevant context and constraints
5. Optimize for the target LLM's strengths and limitations

## Output Format

<analysis>
  [Detailed analysis of the original prompt, identifying strengths and areas for improvement]
</analysis>

<optimized_prompt_v1>
  [First iteration of the improved prompt]
</optimized_prompt_v1>

<applied_techniques>
  [Explanation of the techniques and strategies used in the optimization]
</applied_techniques>

<evaluation>
  [Assessment of the optimized prompt against key metrics: clarity, specificity, engagement, versatility, and depth]
</evaluation>

<final_optimized_prompt>
  [Final version of the optimized prompt after iterations and refinements]
</final_optimized_prompt>

<improvement_summary>
  [Summary of key improvements and their expected impact on LLM performance]
</improvement_summary>
